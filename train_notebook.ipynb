{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F6_MIMVZ5IJ"
      },
      "source": [
        "# Train the CNNs as seen in \"Predicting the HER2 status in esophageal cancer from tissue microarrays using convolutional neural networks\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0URM6MKaPg7"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DVztv_JSRGQ"
      },
      "source": [
        "%git clone https://github.com/bozeklab/HER2-overexpression.git\n",
        "%cd ./HER2-overexpression\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision.models import resnet34\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "\n",
        "from src.utils import calculate_weights\n",
        "from src.dataset import DistributedWeightedSampler, ImageDataset\n",
        "from src.models import ResnetABMIL\n",
        "from train import train_step, validate_step"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qoi9CJV4aTS9"
      },
      "source": [
        "### Hyperparams (see repo's readme for more info)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk1Sz-65Svog"
      },
      "source": [
        "task = 'her2-status'\n",
        "model = 'resnet34'\n",
        "img_size = 1024\n",
        "train_csv = './train.csv'\n",
        "val_csv = None\n",
        "weighted_sampler_label = None\n",
        "batch_size = 1\n",
        "num_workers = 0\n",
        "learning_rate = 0.001\n",
        "epochs = 100\n",
        "checkpoints_dir = './checkpoints'\n",
        "scheduler_factor = 0.1\n",
        "scheduler_patience = 10"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmKKMbxvac2J"
      },
      "source": [
        "### Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFM8R5hdOovj"
      },
      "source": [
        "os.makedirs(checkpoints_dir, exist_ok = True)\n",
        "torch.manual_seed(0)\n",
        "if task == 'ihc-score':\n",
        "    num_classes = 4\n",
        "elif task == 'her2-status':\n",
        "    num_classes = 2\n",
        "else:\n",
        "    raise ValueError('Task should be ihc-score or her-status')\n",
        "\n",
        "if model == 'resnet34':\n",
        "    model = resnet34(pretrained = False, num_classes = num_classes).cuda()\n",
        "elif model == 'abmil':\n",
        "    model = ResnetABMIL(num_classes = num_classes).cuda()\n",
        "else:\n",
        "    raise ValueError('Model should be resnet34 or abmil')  \n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_df = pd.read_csv(train_csv)\n",
        "train_dataset = ImageDataset(train_df, fn_col = 'filename', lbl_col = task, transform = train_transform)\n",
        "if weighted_sampler_label == None:\n",
        "    weighted_sampler_label = task\n",
        "weights = calculate_weights(torch.tensor(train_df[weighted_sampler_label].values))\n",
        "train_sampler = WeightedRandomSampler(weights, len(weights))\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=train_sampler)\n",
        "\n",
        "if val_csv != None:\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    val_df = pd.read_csv(val_csv)\n",
        "    val_dataset = ImageDataset(val_df, fn_col = 'filename', lbl_col = task, transform = val_transform)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=1e-8)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=scheduler_factor, patience=scheduler_patience, min_lr=1e-15)\n",
        "\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "epoch0 = 0\n",
        "epoch = epoch0\n",
        "while epoch < epoch0 + epochs:\n",
        "\n",
        "    train_phase_results = train_step(train_loader, model, criterion, optimizer)\n",
        "    val_phase_results = {'Loss': '', 'Accuracy' : ''} \n",
        "    if val_csv != None:\n",
        "        val_phase_results = validate_step(val_loader, model, criterion)\n",
        "        acc = val_phase_results['Accuracy']\n",
        "        scheduler.step(acc)\n",
        "\n",
        "    print('Epoch {} finished.'.format(epoch))\n",
        "    print('Train phase: ', train_phase_results)\n",
        "    print('Val phase: ', val_phase_results)\n",
        "    print('\\n')\n",
        "\n",
        "    torch.save({\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'accuracy': val_phase_results['Accuracy']\n",
        "\n",
        "    }, os.path.join(checkpoints_dir,'checkpoint_{}.pth.tar'.format(epoch)))\n",
        "    epoch += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}